{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fa30dcfccf24df975a63e38b1563830b9c91e894"
   },
   "source": [
    "###### Reference\n",
    "https://www.kaggle.com/gpreda/santander-eda-and-prediction  \n",
    "https://www.kaggle.com/deepak525/sctp-lightgbm-lb-0-899  \n",
    "target 1的标签占比约10%  \n",
    "没有缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from datetime import datetime as dt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test.csv', 'sample_submission.csv', 'train.csv']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "9cfc6228ed99f045fbb9897f26dff791ad2952e3",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/train.csv').drop(\"ID_code\",axis=1)\n",
    "test_df = pd.read_csv('../input/test.csv').drop(\"ID_code\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "bd184fb097d935120a693495d40c932106b20dca"
   },
   "outputs": [],
   "source": [
    "df_train = train_df.drop([\"target\"],axis=1).values\n",
    "\n",
    "unique_samples = []\n",
    "unique_count = np.zeros_like(df_train)\n",
    "for feature in range(df_train.shape[1]):\n",
    "    _, index_, count_ = np.unique(df_train[:, feature], return_counts=True, return_index=True)\n",
    "    unique_count[index_[count_ == 1], feature] += 1\n",
    "\n",
    "real_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) > 0)[:, 0]\n",
    "synthetic_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) == 0)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_data(train_df, test_df):\n",
    "    idx = [c for c in train_df.columns if c not in ['ID_code', 'target']]\n",
    "    df = pd.concat([train_df,test_df.ix[real_samples_indexes]])\n",
    "    for feat in idx:\n",
    "        train_df[feat + \"_count\"] = train_df[feat].map(df[feat].value_counts(dropna=True)) \n",
    "        test_df[feat + \"_count\"] = test_df[feat].map(df[feat].value_counts(dropna=True))\n",
    "        \n",
    "        train_df[feat + \"_sum\"] = train_df[feat].map(df.groupby(feat)[feat].sum()) \n",
    "        test_df[feat + \"_sum\"] = test_df[feat].map(df.groupby(feat)[feat].sum()) \n",
    "        \n",
    "        train_df[feat+\"_copy\"] = train_df[feat] * (train_df[feat + \"_count\"] > 1).astype(int)\n",
    "        test_df[feat+\"_copy\"] = test_df[feat] * (test_df[feat + \"_count\"] > 1).astype(int)\n",
    "        train_df[feat+\"_copy\"] = train_df[feat+\"_copy\"].replace(0,df[feat].mean())\n",
    "        test_df[feat+\"_copy\"] = test_df[feat+\"_copy\"].replace(0,df[feat].mean())\n",
    "        \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df, test_df = process_data(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "ca4fbaa11bd784bc72c1d6635fcc210d74ea5d54",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params ={\n",
    "    'bagging_freq': 5,\n",
    "    'bagging_fraction': 0.33,\n",
    "    'boost_from_average':'false',\n",
    "    'boost': 'gbdt',\n",
    "    'feature_fraction': 0.6,\n",
    "    'learning_rate': 0.003,\n",
    "    'max_depth': -1,\n",
    "    'metric':'auc',\n",
    "    'min_data_in_leaf': 80,\n",
    "    'min_sum_hessian_in_leaf': 10.0,\n",
    "    'num_leaves': 13,\n",
    "    'device':'gpu',  \n",
    "    'gpu_platform_id': 0,\n",
    "    'gpu_device_id': 0,\n",
    "    'num_threads': 2,\n",
    "    'tree_learner': 'serial',\n",
    "    'objective': 'binary',\n",
    "    'verbosity': 1\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "73d0bf713c71b128fd67e293a795dc11573835d3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=4590)\n",
    "train_features = [c for c in train_df.columns if c not in ['ID_code', 'target']]\n",
    "y = train_df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "da05e647c825cdf1a68d0e448388f4a21be98a52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 started at Mon Apr  1 15:06:57 2019\n",
      "Training until validation scores don't improve for 3500 rounds.\n",
      "[2000]\tvalid_0's auc: 0.877781\n",
      "[4000]\tvalid_0's auc: 0.902781\n",
      "[6000]\tvalid_0's auc: 0.912999\n",
      "[8000]\tvalid_0's auc: 0.918099\n",
      "[10000]\tvalid_0's auc: 0.920899\n",
      "[12000]\tvalid_0's auc: 0.922555\n",
      "[14000]\tvalid_0's auc: 0.923476\n",
      "[16000]\tvalid_0's auc: 0.923996\n",
      "[18000]\tvalid_0's auc: 0.924292\n",
      "[20000]\tvalid_0's auc: 0.924431\n",
      "[22000]\tvalid_0's auc: 0.924558\n",
      "[24000]\tvalid_0's auc: 0.924634\n",
      "[26000]\tvalid_0's auc: 0.924543\n",
      "Early stopping, best iteration is:\n",
      "[23315]\tvalid_0's auc: 0.924662\n",
      "Fold 2 started at Mon Apr  1 15:39:51 2019\n",
      "Training until validation scores don't improve for 3500 rounds.\n",
      "[2000]\tvalid_0's auc: 0.868286\n",
      "[4000]\tvalid_0's auc: 0.896369\n",
      "[6000]\tvalid_0's auc: 0.907681\n",
      "[8000]\tvalid_0's auc: 0.913678\n",
      "[10000]\tvalid_0's auc: 0.91719\n",
      "[12000]\tvalid_0's auc: 0.919192\n",
      "[14000]\tvalid_0's auc: 0.920474\n",
      "[16000]\tvalid_0's auc: 0.921243\n",
      "[18000]\tvalid_0's auc: 0.921626\n",
      "[20000]\tvalid_0's auc: 0.921903\n",
      "[22000]\tvalid_0's auc: 0.921989\n",
      "[24000]\tvalid_0's auc: 0.92205\n",
      "[26000]\tvalid_0's auc: 0.922087\n",
      "[28000]\tvalid_0's auc: 0.922108\n",
      "[30000]\tvalid_0's auc: 0.922107\n",
      "[32000]\tvalid_0's auc: 0.922106\n",
      "Early stopping, best iteration is:\n",
      "[29817]\tvalid_0's auc: 0.922141\n",
      "Fold 3 started at Mon Apr  1 16:21:11 2019\n",
      "Training until validation scores don't improve for 3500 rounds.\n",
      "[2000]\tvalid_0's auc: 0.865512\n",
      "[4000]\tvalid_0's auc: 0.894296\n",
      "[6000]\tvalid_0's auc: 0.906349\n",
      "[8000]\tvalid_0's auc: 0.912802\n",
      "[10000]\tvalid_0's auc: 0.916521\n",
      "[12000]\tvalid_0's auc: 0.918595\n",
      "[14000]\tvalid_0's auc: 0.919954\n",
      "[16000]\tvalid_0's auc: 0.920785\n",
      "[18000]\tvalid_0's auc: 0.921359\n",
      "[20000]\tvalid_0's auc: 0.921826\n",
      "[22000]\tvalid_0's auc: 0.921968\n",
      "[24000]\tvalid_0's auc: 0.922085\n",
      "[26000]\tvalid_0's auc: 0.922169\n",
      "[28000]\tvalid_0's auc: 0.922179\n",
      "[30000]\tvalid_0's auc: 0.922139\n",
      "Early stopping, best iteration is:\n",
      "[28350]\tvalid_0's auc: 0.922226\n",
      "Fold 4 started at Mon Apr  1 17:01:38 2019\n",
      "Training until validation scores don't improve for 3500 rounds.\n",
      "[2000]\tvalid_0's auc: 0.870495\n",
      "[4000]\tvalid_0's auc: 0.897291\n",
      "[6000]\tvalid_0's auc: 0.908179\n",
      "[8000]\tvalid_0's auc: 0.913671\n",
      "[10000]\tvalid_0's auc: 0.91687\n",
      "[12000]\tvalid_0's auc: 0.918693\n",
      "[14000]\tvalid_0's auc: 0.919844\n",
      "[16000]\tvalid_0's auc: 0.920484\n",
      "[18000]\tvalid_0's auc: 0.920916\n",
      "[20000]\tvalid_0's auc: 0.921085\n",
      "[22000]\tvalid_0's auc: 0.921276\n",
      "[24000]\tvalid_0's auc: 0.921269\n",
      "[26000]\tvalid_0's auc: 0.921283\n",
      "[28000]\tvalid_0's auc: 0.921254\n",
      "Early stopping, best iteration is:\n",
      "[26264]\tvalid_0's auc: 0.921315\n",
      "Fold 5 started at Mon Apr  1 17:40:22 2019\n",
      "Training until validation scores don't improve for 3500 rounds.\n",
      "[2000]\tvalid_0's auc: 0.863999\n",
      "[4000]\tvalid_0's auc: 0.89383\n",
      "[6000]\tvalid_0's auc: 0.906083\n",
      "[8000]\tvalid_0's auc: 0.912273\n",
      "[10000]\tvalid_0's auc: 0.915609\n",
      "[12000]\tvalid_0's auc: 0.91774\n",
      "[14000]\tvalid_0's auc: 0.919059\n",
      "[16000]\tvalid_0's auc: 0.919793\n",
      "[18000]\tvalid_0's auc: 0.920181\n",
      "[20000]\tvalid_0's auc: 0.920449\n",
      "[22000]\tvalid_0's auc: 0.920665\n",
      "[24000]\tvalid_0's auc: 0.920788\n",
      "[26000]\tvalid_0's auc: 0.920888\n",
      "[28000]\tvalid_0's auc: 0.920911\n",
      "[30000]\tvalid_0's auc: 0.920925\n",
      "Early stopping, best iteration is:\n",
      "[28466]\tvalid_0's auc: 0.920963\n",
      "AUC is  0.9222326201771407\n"
     ]
    }
   ],
   "source": [
    "oof_preds = np.zeros(train_df.shape[0])\n",
    "sub_preds = np.zeros(test_df.shape[0])\n",
    "clfs = list()\n",
    "\n",
    "for fold_n, (train_index, valid_index) in enumerate(folds.split(train_df,y)):\n",
    "    print('Fold', fold_n+1, 'started at', time.ctime())\n",
    "    X_train, y_train = train_df.iloc[train_index], y.iloc[train_index]\n",
    "    X_valid, y_valid = train_df.iloc[valid_index], y.iloc[valid_index]\n",
    "        \n",
    "    train_data = lgb.Dataset(X_train[train_features], label=y_train,)\n",
    "    valid_data = lgb.Dataset(X_valid[train_features], label=y_valid)\n",
    "        \n",
    "    model = lgb.train(params,\n",
    "                      train_data,\n",
    "                      num_boost_round=100000,\n",
    "                      valid_sets = [valid_data],\n",
    "                      verbose_eval=2000,\n",
    "                      early_stopping_rounds=3500,)\n",
    "    \n",
    "    oof_preds[valid_index] += model.predict(X_valid[train_features], num_iteration=model.best_iteration)\n",
    "    sub_preds += model.predict(test_df[train_features], num_iteration=model.best_iteration)/n_fold\n",
    "    del X_train, X_valid, y_train, y_valid,train_data,valid_data    \n",
    "    gc.collect()\n",
    "print('AUC is ', roc_auc_score(y, oof_preds))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "36f81e66eb207bf7b7c1f9ca848d9a46f0c6f1bf"
   },
   "outputs": [],
   "source": [
    "auc = roc_auc_score(y, oof_preds)\n",
    "oof_train = oof_preds\n",
    "oof_test = sub_preds\n",
    "submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "submission[\"target\"] = oof_test\n",
    "submission.to_csv(\"./sub/submission_%s.csv\"%auc, index=False)\n",
    "\n",
    "train_prob  = pd.DataFrame(oof_train)\n",
    "train_prob.columns = ['class_1']\n",
    "train_prob.to_csv(\"./oof/lgb_oof_train_%s.csv\"%auc,index=False)\n",
    "\n",
    "test_prob= pd.DataFrame(oof_test)\n",
    "test_prob.columns = ['class_1']\n",
    "test_prob.to_csv(\"./oof/lgb_oof_test_%s.csv\"%auc,index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "17e50fb8308ee2caf5f7ab3a8deff6660e9048f7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_importance_ = pd.DataFrame({\"feature\":train_features, \n",
    "                                 \"importance\":np.mean([clf.feature_importance(importance_type=\"gain\") for clf in clfs],axis=0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "902bbff15ec56a10f1fd8be86255a0eeaa6e8c95",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Display/plot feature importance\n",
    "def display_importances(feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "        by=\"importance\", ascending=False)[:100].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "\n",
    "    plt.figure(figsize=(8, 20))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('lgbm_importances.png')\n",
    "    \n",
    "display_importances(feat_importance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
